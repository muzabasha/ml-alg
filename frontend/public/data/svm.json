{
    "id": "svm",
    "name": "Support Vector Machine (SVM)",
    "category": "Supervised Learning - Classification",
    "difficulty": "Advanced",
    "estimatedTime": "60 minutes",
    "sections": {
        "introduction": {
            "title": "Introduction to Support Vector Machines",
            "plainLanguage": "SVM finds the best boundary (hyperplane) that separates different classes with maximum margin. It's like drawing a line between two groups of points, but making sure the line is as far as possible from both groups.",
            "realWorldAnalogy": "Imagine you're a referee separating two arguing teams. You position yourself exactly in the middle, maximizing distance from both sides.",
            "whereAndWhy": "Used for text classification, image recognition, bioinformatics.",
            "learningType": "Supervised Learning",
            "strengths": [
                "Effective in high-dimensional spaces",
                "Memory efficient",
                "Versatile kernels"
            ],
            "limitations": [
                "Slow to train on large datasets",
                "Sensitive to scaling"
            ]
        },
        "mathematical_model": {
            "title": "Mathematical Formulation",
            "introduction": "SVM maximizes the margin between classes.",
            "equations": [
                {
                    "name": "Decision Boundary",
                    "latex": "f(x) = w^T x + b",
                    "explanation": "Points where f(x)=0 form the boundary."
                },
                {
                    "name": "Margin",
                    "latex": "\\frac{2}{||w||}",
                    "explanation": "Distance to nearest points."
                }
            ],
            "keyTerms": {
                "Support Vectors": "Training points closest to boundary",
                "Kernel": "Function for non-linear boundaries"
            },
            "intuition": "SVM finds the widest 'street' separating neighborhoods."
        },
        "sample_io": {
            "title": "Sample Input & Output",
            "description": "Binary classification of points.",
            "input": {
                "format": "2D points",
                "table": [
                    {
                        "X1": 1,
                        "X2": 2,
                        "Class": -1
                    },
                    {
                        "X1": 5,
                        "X2": 5,
                        "Class": 1
                    }
                ]
            },
            "output": {
                "margin": 1.25,
                "n_support_vectors": 2
            },
            "visualization": "Scatter plot with decision boundary and margin."
        },
        "implementation_scratch": {
            "title": "Python Implementation (From Scratch)",
            "description": "Simplified SVM using gradient descent.",
            "code": "import numpy as np\nclass SVM:\n    def fit(self, X, y):\n        self.w = np.zeros(X.shape[1])\n        self.b = 0\n        for _ in range(1000):\n            for i, x_i in enumerate(X):\n                if y[i] * (np.dot(x_i, self.w) - self.b) >= 1:\n                    self.w -= 0.001 * (2 * 0.01 * self.w)\n                else:\n                    self.w -= 0.001 * (2 * 0.01 * self.w - np.dot(x_i, y[i]))\n                    self.b -= 0.001 * y[i]"
        },
        "implementation_api": {
            "title": "Python Implementation (Using scikit-learn)",
            "description": "Production-ready SVM.",
            "code": "from sklearn.svm import SVC\nmodel = SVC(kernel='linear')\nmodel.fit(X, y)"
        },
        "evaluation": {
            "title": "Model Evaluation",
            "why": "Generalization is key for SVM.",
            "metrics": [
                {
                    "name": "Accuracy",
                    "formula": "Correct / Total",
                    "interpretation": "Overall correctness."
                }
            ]
        },
        "improvements": {
            "title": "Ways to Improve Performance",
            "featureEngineering": [
                "Scaling (Critical!)"
            ],
            "hyperparameterTuning": [
                "C parameter",
                "Kernel choice"
            ],
            "dataPreprocessing": [
                "Handle class imbalance"
            ]
        }
    }
}